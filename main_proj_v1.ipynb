{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/rdj0im/rl-atsc/blob/main/main_proj_v1.ipynb","timestamp":1682749181016}],"private_outputs":true,"gpuType":"T4","mount_file_id":"1n2nmLWrPeu9UR78m95CzgFtz2lYacy0Z","authorship_tag":"ABX9TyM7BXvycbwxU5Bcm/6EZ/8h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Mount GDrive"],"metadata":{"id":"tmRwha3Vs8SH"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"bJK5eLcDs7xD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Setup working directory"],"metadata":{"id":"Vnt8OIqEe8Z2"}},{"cell_type":"code","source":["import os\n","# set base dir\n","BASE_DIR='main_proj_v1' \n","os.environ['BASE_DIR'] = 'main_proj_v1'\n","\n","!git init .\n","!git remote add -t * -f origin https://github.com/rdj0im/rl-atsc.git\n","!git checkout master\n","\n","!mkdir -p $BASE_DIR\n","!mkdir -p  /content/gdrive/MyDrive/models\n","!mkdir -p  /content/gdrive/MyDrive/models/outputs\n","os.chdir(BASE_DIR)\n","# get git repo\n","!git init .\n","!git remote add -t * -f origin https://github.com/rdj0im/rl-atsc.git\n","!git checkout main\n","# set up credentials\n","!sed -i '/\\[remote \\\"origin\\\"\\]/Q' .git/config\n","!cat /content/gdrive/MyDrive/Colab\\ Notebooks/config >> .git/config"],"metadata":{"id":"p9OZ_X7Mt7VX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Install SUMO"],"metadata":{"id":"77a4anb8irRe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iC08dVJofoxr"},"outputs":[],"source":["!sudo add-apt-repository -y ppa:sumo/stable\n","!sudo apt-get update\n","!sudo apt-get -y install sumo sumo-tools sumo-doc &\n"]},{"cell_type":"markdown","source":["Set sumo env vars"],"metadata":{"id":"TF_SPd08ikyu"}},{"cell_type":"code","source":["# Set environment variable\n","os.environ['SUMO_HOME'] = '/usr/share/sumo'\n","os.environ['LIBSUMO_AS_TRACI'] = '1' #Optional: for a huge performance boost (~8x) with Libsumo (No GUI)"],"metadata":{"id":"bFZ6ugYLiKpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**SUMO RL**"],"metadata":{"id":"q34uA3wHi1Ou"}},{"cell_type":"markdown","source":["Install modules"],"metadata":{"id":"Ur-8tiWTjABo"}},{"cell_type":"code","source":["# !pip install 'setuptools<67'\n","# !pip install gym==0.21.0\n","# !pip install stable_baselines3\n","# !pip install git+https://github.com/DLR-RM/stable-baselines3.git\n","# !pip install sumo-rl\n","# !pip install -U ray[rllib] tensorflow torchh\n","!pip install -U -r requirements.txt\n","!pip install torch"],"metadata":{"id":"c6dQ1evZjCTv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Main\n","\n"],"metadata":{"id":"UD9am7Udeju3"}},{"cell_type":"markdown","source":["Imports and env setup"],"metadata":{"id":"kxhEDjVwdjcX"}},{"cell_type":"code","source":["import os\n","import sys\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","if \"SUMO_HOME\" in os.environ:\n","    tools = os.path.join(os.environ[\"SUMO_HOME\"], \"tools\")\n","    sys.path.append(tools)\n","else:\n","    sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")\n","import traci\n","import sumo_rl\n"],"metadata":{"id":"4l91gEosdml5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Global Variables"],"metadata":{"id":"qlninHoldshj"}},{"cell_type":"code","source":[],"metadata":{"id":"hae62n1udu3_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Actor Model\n"],"metadata":{"id":"0vEuIgVudGNl"}},{"cell_type":"code","source":["\n","class ActorModel(nn.Module):\n","    def __init__(self, wave_n, wait_n, neighbour_s_n,phases_n):\n","        super(ActorModel, self).__init__()\n","        self.wave_n=wave_n\n","        self.wait_n=wait_n\n","        self.neighbour_s_n=neighbour_s_n\n","        # Define the three FC layers with input sizes wave_n, wait_n, and neighbour_s_n\n","        self.fc1 = nn.Linear(wave_n, 128)\n","        self.fc2 = nn.Linear(wait_n, 32)\n","        self.fc3 = nn.Linear(neighbour_s_n, 64)\n","        # unbatched\n","        '''\n","        h_0: tensor of shape (Dâˆ—num_layers,Hout)(Dâˆ—num_layers,Houtâ€‹) for unbatched input or (Dâˆ—num_layers,N,Hout)(Dâˆ—num_layers,N,Houtâ€‹) containing the initial hidden state for each element in the input sequence. Defaults to zeros if (h_0, c_0) is not provided.\n","\n","        c_0: tensor of shape (Dâˆ—num_layers,Hcell)(Dâˆ—num_layers,Hcellâ€‹) for unbatched input or (Dâˆ—num_layers,N,Hcell)(Dâˆ—num_layers,N,Hcellâ€‹) containing the initial cell state for each element in the input sequence. Defaults to zeros if (h_0, c_0) is not provided.\n","        '''\n","        self.hn = Variable(torch.zeros(1*1,548))\n","        self.cn = Variable(torch.zeros(1*1,548))\n","        # Define the LSTM layer\n","        self.lstm = nn.LSTM(input_size=224, hidden_size=548, num_layers=1)\n","        self.linear=nn.Linear(548,phases_n)\n","        self.softmax=nn.Softmax(dim=1)\n","    def forward(self, wave,wait,neighbour_s):\n","        # Pass input through the three FC layers\n","        x1 = self.fc1(wave)\n","        x2 = self.fc2(wait)\n","        x3 = self.fc3(neighbour_s)\n","        \n","        # Combine the outputs of the FC layers\n","        combined = torch.cat((x1, x2, x3), dim=1)\n","        \n","        # Prepare input for LSTM layer\n","        '''\n","        input: tensor of shape (L,Hin)(L,Hinâ€‹) for unbatched input, (L,N,Hin)(L,N,Hinâ€‹) when batch_first=False or (N,L,Hin)(N,L,Hinâ€‹) when batch_first=True containing the features of the input sequence. \n","        where:\n","        N=batch sizeL=sequence lengthD=2 if bidirectional=True otherwise 1Hin=input_sizeHcell=hidden_sizeHout=proj_size if proj_size>0 otherwise hidden_size\n","        N=L=D=Hinâ€‹=Hcellâ€‹=Houtâ€‹=â€‹batch sizesequence length2 if bidirectional=True otherwise 1input_sizehidden_sizeproj_size if proj_size>0 otherwise hidden_sizeâ€‹\n","        '''\n","        lstm_input = combined.view(1, 224)\n","        \n","        # Initialize hidden state and cell state for LSTM layer\n","        \n","        \n","        # Pass input through the LSTM layer\n","        lstm_output, (hn, cn) = self.lstm(lstm_input, (hn, cn))\n","\n","        '''\n","        output: tensor of shape (L,Dâˆ—Hout)(L,Dâˆ—Houtâ€‹) for unbatched input, (L,N,Dâˆ—Hout)(L,N,Dâˆ—Houtâ€‹) when batch_first=False or (N,L,Dâˆ—Hout)(N,L,Dâˆ—Houtâ€‹) when batch_first=True containing the output features (h_t) from the last layer of the LSTM, for each t\n","        '''\n","        lin_outp=self.linear(lstm_output[:,:])\n","        softmax_output=self.softmax(lin_outp)\n","        return softmax_output\n"],"metadata":{"id":"dRFC1qy_dIux"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Critic Model"],"metadata":{"id":"VwMgAnhYdJiz"}},{"cell_type":"code","source":["\n","class CriticModel(nn.Module):\n","    def __init__(self, wave_n, wait_n, neighbour_s_n):\n","        super(CriticModel, self).__init__()\n","        self.wave_n=wave_n\n","        self.wait_n=wait_n\n","        self.neighbour_s_n=neighbour_s_n\n","        # Define the three FC layers with input sizes wave_n, wait_n, and neighbour_s_n\n","        self.fc1 = nn.Linear(wave_n, 128)\n","        self.fc2 = nn.Linear(wait_n, 32)\n","        self.fc3 = nn.Linear(neighbour_s_n, 64)\n","        # unbatched\n","        '''\n","        h_0: tensor of shape (Dâˆ—num_layers,Hout)(Dâˆ—num_layers,Houtâ€‹) for unbatched input or (Dâˆ—num_layers,N,Hout)(Dâˆ—num_layers,N,Houtâ€‹) containing the initial hidden state for each element in the input sequence. Defaults to zeros if (h_0, c_0) is not provided.\n","\n","        c_0: tensor of shape (Dâˆ—num_layers,Hcell)(Dâˆ—num_layers,Hcellâ€‹) for unbatched input or (Dâˆ—num_layers,N,Hcell)(Dâˆ—num_layers,N,Hcellâ€‹) containing the initial cell state for each element in the input sequence. Defaults to zeros if (h_0, c_0) is not provided.\n","        '''\n","        self.hn = Variable(torch.zeros(1*1,548))\n","        self.cn = Variable(torch.zeros(1*1,548))\n","        # Define the LSTM layer\n","        self.lstm = nn.LSTM(input_size=224, hidden_size=548, num_layers=1)\n","        self.linear=nn.Linear(548,1)\n","    def forward(self, wave,wait,neighbour_s):\n","        # Pass input through the three FC layers\n","        x1 = self.fc1(wave)\n","        x2 = self.fc2(wait)\n","        x3 = self.fc3(neighbour_s)\n","        \n","        # Combine the outputs of the FC layers\n","        combined = torch.cat((x1, x2, x3), dim=1)\n","        \n","        # Prepare input for LSTM layer\n","        '''\n","        input: tensor of shape (L,Hin)(L,Hinâ€‹) for unbatched input, (L,N,Hin)(L,N,Hinâ€‹) when batch_first=False or (N,L,Hin)(N,L,Hinâ€‹) when batch_first=True containing the features of the input sequence. \n","        where:\n","        N=batch sizeL=sequence lengthD=2 if bidirectional=True otherwise 1Hin=input_sizeHcell=hidden_sizeHout=proj_size if proj_size>0 otherwise hidden_size\n","        N=L=D=Hinâ€‹=Hcellâ€‹=Houtâ€‹=â€‹batch sizesequence length2 if bidirectional=True otherwise 1input_sizehidden_sizeproj_size if proj_size>0 otherwise hidden_sizeâ€‹\n","        '''\n","        lstm_input = combined.view(1, 224)\n","        \n","        # Initialize hidden state and cell state for LSTM layer\n","        \n","        \n","        # Pass input through the LSTM layer\n","        lstm_output, (hn, cn) = self.lstm(lstm_input, (hn, cn))\n","\n","        '''\n","        output: tensor of shape (L,Dâˆ—Hout)(L,Dâˆ—Houtâ€‹) for unbatched input, (L,N,Dâˆ—Hout)(L,N,Dâˆ—Houtâ€‹) when batch_first=False or (N,L,Dâˆ—Hout)(N,L,Dâˆ—Houtâ€‹) when batch_first=True containing the output features (h_t) from the last layer of the LSTM, for each t\n","        '''\n","        lin_outp=self.linear(lstm_output[:,:])\n","\n","        return lstm_output\n","        "],"metadata":{"id":"BBQZvmIFdLgW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Main func"],"metadata":{"id":"9UQLeGYkdSQ3"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    env = sumo_rl.parallel_env(\n","        # net_file=\"sumo_files/4x4_grid_network.net.xml\",\n","        # route_file=\"sumo_files/4x4_grid_routes.rou.xml\",\n","        net_file=\"sumo_files/v1_4x4_grid.net.xml\",\n","        route_file=\"sumo_files/v1_4x4_grid.rou.xml\",\n","        # net_file=\"sumo_files/chry-test.net.xml\",\n","        # route_file=\"sumo_files/chry-trips.trips.xml\",\n","        out_csv_name=\"outputs/\",\n","        single_agent=False,\n","        use_gui=False,\n","        # begin_time=10,\n","        num_seconds=5000000,\n","        min_green=5,\n","        max_green=60,\n","        delta_time=5\n","    )\n","    observation=env.reset(seed=33)\n","    while agents:=env.agents:\n","    # this is where you would insert your policy\n","        a_s={agent: env.action_space(agent) for agent in agents}\n","        actions = {agent: env.action_space(agent).sample() for agent in agents}  \n","        observations, rewards, terminations, truncations, infos = env.step(actions)\n","        pass\n","    env.close()"],"metadata":{"id":"d4DtqM52Zvlg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**---------------------------------------------------------------     Code Ends Here    ------------------------------------------------------------------**"],"metadata":{"id":"ULI02_1sZ14I"}},{"cell_type":"markdown","source":["\n","---\n","\n","**Save, Commit and Push**"],"metadata":{"id":"szd3S40wtXvG"}},{"cell_type":"code","source":["# import time\n","# from IPython.display import display, Javascript\n","# import hashlib\n","\n","# # trigger save of current notebook \n","\n","# def save_notebook(file_path):\n","#     start_md5 = hashlib.md5(open(file_path,'rb').read()).hexdigest()\n","#     display(Javascript('IPython.notebook.save_checkpoint();'))\n","#     current_md5 = start_md5\n","\n","#     while start_md5 == current_md5:\n","#         time.sleep(1)\n","#         current_md5 = hashlib.md5(open(file_path,'rb').read()).hexdigest()\n","\n","# copy saved nb to current dir\n","# file_path='/content/gdrive/MyDrive/Colab Notebooks/main_proj_v1.ipynb'\n","# save_notebook(file_path)\n","\n","# ðŸ¥²\n","# ''' Trigger a Save using Ctrl+S beforehand '''\n","# ðŸ¥²\n","\n","!cp /content/gdrive/MyDrive/Colab\\ Notebooks/main_proj_v1.ipynb main_proj_v1.ipynb \n","# push to remote\n","!git add -A\n","!git commit -m \"ipynb save triggered from nb\"\n","!git push\n"],"metadata":{"id":"d2E8C2_85Qmm"},"execution_count":null,"outputs":[]}]}